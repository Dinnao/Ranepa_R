### PATH
- [__lecture slides__](../resources/slides/nlp19_01_word_embeddings.pdf)
- Our videos: [__intro__](https://yadi.sk/i/BNTJG-_rwf20Gw), [__lecture__](https://yadi.sk/i/nUiHl4VPMOCz0g), [__seminar__](https://yadi.sk/i/QTcGA5mgdhS8jg)
- Lecture video from Stanford CS224N - [__intro__](https://www.youtube.com/watch?v=OQQ-W_63UgQ), [__embeddings__](https://www.youtube.com/watch?v=ERibwqs9p38) (english)


### Practice & homework
The practice for this week takes place in notebooks. Just open them and follow instructions from there.
* __Seminar:__ `./seminar.ipynb`
* __Homework:__ `./homework.ipynb`

Unless explicitly said otherwise, all subsequent weeks follow the same pattern (notebook with instructions).

If you have any difficulties with notebooks, just open them in [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yandexdataschool/nlp_course/blob/master/week01_embeddings/seminar.ipynb).

#### Embedding space walk
![embedding_space_walk](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/embedding_space_walk.gif)

### More materials (optional)
* On hierarchical & sampled softmax estimation for word2vec [page](http://ruder.io/word-embeddings-softmax/)
* GloVe project [page](https://nlp.stanford.edu/projects/glove/)
* FastText project [repo](https://github.com/facebookresearch/fastText)
* Semantic change over time - oberved through word embeddings - [arxiv](https://arxiv.org/pdf/1605.09096.pdf)
* Another cool link that you could have shared, but decided to hesitate. Or did you?

